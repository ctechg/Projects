{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95762d10-286f-41da-9466-a96d22c7984d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer features with all regions saved to 'Customer_Features_Keep_All_Regions.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "customers_df = pd.read_csv('Customers.csv')\n",
    "transactions_df = pd.read_csv('Transactions.csv')\n",
    "products_df = pd.read_csv('Products.csv')\n",
    "\n",
    "# --- 1. Region (Encoded) ---\n",
    "# One-hot encode the 'Region' column without dropping the first category\n",
    "customers_df = pd.get_dummies(customers_df, columns=['Region'], drop_first=False)\n",
    "\n",
    "# --- 2. Total Number of Transactions ---\n",
    "# Count the total number of transactions for each customer\n",
    "total_transactions = transactions_df.groupby('CustomerID').size().reset_index(name='Total No of Transactions')\n",
    "customers_df = customers_df.merge(total_transactions, on='CustomerID', how='left')\n",
    "\n",
    "# --- 3. Total Spend ---\n",
    "# Calculate the total spend for each customer\n",
    "total_spend = transactions_df.groupby('CustomerID')['TotalValue'].sum().reset_index(name='Total Spend')\n",
    "customers_df = customers_df.merge(total_spend, on='CustomerID', how='left')\n",
    "\n",
    "# --- 4. Average Transaction Value ---\n",
    "# Calculate the average transaction value\n",
    "customers_df['Average Transaction Value'] = customers_df['Total Spend'] / customers_df['Total No of Transactions']\n",
    "\n",
    "# --- 5. Category Spend ---\n",
    "# Merge transactions with products to get the product category\n",
    "transactions_with_category = transactions_df.merge(products_df[['ProductID', 'Category']], on='ProductID', how='left')\n",
    "\n",
    "# Calculate total spend per category for each customer\n",
    "category_spend = transactions_with_category.groupby(['CustomerID', 'Category'])['TotalValue'].sum().reset_index(name='Category Spend')\n",
    "\n",
    "# Pivot the table to get each category as a separate column for spend\n",
    "category_spend_pivot = category_spend.pivot(index='CustomerID', columns='Category', values='Category Spend').fillna(0)\n",
    "\n",
    "# Merge with the customers dataframe\n",
    "customers_df = customers_df.merge(category_spend_pivot, on='CustomerID', how='left')\n",
    "\n",
    "# --- 6. Category Frequency ---\n",
    "# Count the number of transactions per category for each customer\n",
    "category_frequency = transactions_with_category.groupby(['CustomerID', 'Category']).size().reset_index(name='Category Frequency')\n",
    "\n",
    "# Pivot the table to get each category as a separate column for frequency\n",
    "category_frequency_pivot = category_frequency.pivot(index='CustomerID', columns='Category', values='Category Frequency').fillna(0)\n",
    "\n",
    "# Merge with the customers dataframe\n",
    "customers_df = customers_df.merge(category_frequency_pivot, on='CustomerID', how='left')\n",
    "\n",
    "\n",
    "# Save the final dataframe with features\n",
    "customers_df.to_csv('Customer_Features_Keep_All_Regions_.csv', index=False)\n",
    "\n",
    "print(\"Customer features with all regions saved to 'Customer_Features_Keep_All_Regions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82f4fe23-4782-4efd-b649-98e7eb12cb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID                   0\n",
      "CustomerName                 0\n",
      "SignupDate                   0\n",
      "Region_Asia                  0\n",
      "Region_Europe                0\n",
      "Region_North America         0\n",
      "Region_South America         0\n",
      "Total No of Transactions     1\n",
      "Total Spend                  1\n",
      "Average Transaction Value    1\n",
      "Books_x                      1\n",
      "Clothing_x                   1\n",
      "Electronics_x                1\n",
      "Home Decor_x                 1\n",
      "Books_y                      1\n",
      "Clothing_y                   1\n",
      "Electronics_y                1\n",
      "Home Decor_y                 1\n",
      "dtype: int64\n",
      "Lookalike.csv has been saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 1: Load the customer features CSV\n",
    "customers_df = pd.read_csv('Customer_Features_Keep_All_Regions.csv')\n",
    "\n",
    "# Step 2: Check for missing values\n",
    "print(customers_df.isnull().sum())\n",
    "\n",
    "# Fill missing values with 0\n",
    "customers_df.fillna(0, inplace=True)\n",
    "\n",
    "# Step 3: Data Preprocessing\n",
    "# Extract relevant columns for similarity calculation\n",
    "features = customers_df.drop(columns=['CustomerID', 'CustomerName', 'SignupDate'])\n",
    "\n",
    "# Convert Region columns (TRUE/FALSE) to numerical values (1/0)\n",
    "region_columns = ['Region_Asia', 'Region_Europe', 'Region_North America', 'Region_South America']\n",
    "features[region_columns] = features[region_columns].astype(int)\n",
    "\n",
    "# Standardize the numerical features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Step 4: Compute Cosine Similarity\n",
    "# Compute cosine similarity between all customers\n",
    "similarity_matrix = cosine_similarity(scaled_features)\n",
    "\n",
    "# Step 5: Generate Lookalike Recommendations\n",
    "lookalikes = {}\n",
    "\n",
    "# For customers C0001 to C0020, we want to find the top 3 similar customers\n",
    "for i in range(20):  # For customers C0001 to C0020\n",
    "    cust_id = customers_df.loc[i, 'CustomerID']\n",
    "    \n",
    "    # Get the similarity scores for the current customer (row in the matrix)\n",
    "    similarity_scores = similarity_matrix[i]\n",
    "    \n",
    "    # Exclude the similarity with the customer itself (i.e., 1.0)\n",
    "    similarity_scores[i] = -1  # Assign a very low score to itself to exclude it\n",
    "\n",
    "    # Get the indices of the top 3 most similar customers (excluding itself)\n",
    "    top_3_indices = similarity_scores.argsort()[-3:][::-1]\n",
    "    \n",
    "    # Get the customer IDs and similarity scores for the top 3\n",
    "    top_3_lookalikes = [(customers_df.loc[j, 'CustomerID'], similarity_scores[j]) for j in top_3_indices]\n",
    "    \n",
    "    # Create a list of lookalikes and scores\n",
    "    lookalikes[cust_id] = [(lookalike_cust_id, score) for lookalike_cust_id, score in top_3_lookalikes]\n",
    "\n",
    "# Step 6: Create the Lookalike CSV\n",
    "lookalike_data = []\n",
    "\n",
    "# Convert the lookalikes dictionary to the required format\n",
    "for cust_id, lookalike_list in lookalikes.items():\n",
    "    lookalike_data.append({\n",
    "        'cust_id': cust_id,\n",
    "        'lookalike_cust_ids_and_scores': str(lookalike_list)  # Convert the list of lookalikes to a string\n",
    "    })\n",
    "\n",
    "lookalike_df = pd.DataFrame(lookalike_data)\n",
    "\n",
    "# Save to CSV\n",
    "lookalike_df.to_csv('Chirag_Gupta_Lookalike.csv', index=False)\n",
    "\n",
    "print(\"Lookalike.csv has been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0746fad8-453d-40fa-a285-751514f242d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>lookalike_cust_ids_and_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0001</td>\n",
       "      <td>[('C0091', 0.8908422994906), ('C0120', 0.88625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0002</td>\n",
       "      <td>[('C0134', 0.9330356886590646), ('C0159', 0.91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0003</td>\n",
       "      <td>[('C0031', 0.9195362040251337), ('C0152', 0.80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0004</td>\n",
       "      <td>[('C0113', 0.8681637620310363), ('C0012', 0.83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0005</td>\n",
       "      <td>[('C0007', 0.9595673401635022), ('C0146', 0.88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C0006</td>\n",
       "      <td>[('C0187', 0.7669275518781463), ('C0169', 0.76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C0007</td>\n",
       "      <td>[('C0005', 0.9595673401635022), ('C0140', 0.87...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C0008</td>\n",
       "      <td>[('C0098', 0.7927078262500883), ('C0194', 0.77...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C0009</td>\n",
       "      <td>[('C0198', 0.9338276912431526), ('C0010', 0.84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C0010</td>\n",
       "      <td>[('C0111', 0.9017605958313126), ('C0062', 0.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C0011</td>\n",
       "      <td>[('C0153', 0.8697689581026931), ('C0126', 0.77...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C0012</td>\n",
       "      <td>[('C0104', 0.9139567967558033), ('C0152', 0.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C0013</td>\n",
       "      <td>[('C0188', 0.8763216361016894), ('C0099', 0.86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C0014</td>\n",
       "      <td>[('C0060', 0.9814851639655328), ('C0198', 0.88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C0015</td>\n",
       "      <td>[('C0036', 0.9133874291050558), ('C0144', 0.90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C0016</td>\n",
       "      <td>[('C0183', 0.8171306746865663), ('C0117', 0.77...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C0017</td>\n",
       "      <td>[('C0075', 0.9063812623664969), ('C0057', 0.78...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C0018</td>\n",
       "      <td>[('C0125', 0.8328130980174581), ('C0050', 0.82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C0019</td>\n",
       "      <td>[('C0070', 0.787728756527267), ('C0121', 0.736...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C0020</td>\n",
       "      <td>[('C0050', 0.7949734014471683), ('C0058', 0.78...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_id                      lookalike_cust_ids_and_scores\n",
       "0    C0001  [('C0091', 0.8908422994906), ('C0120', 0.88625...\n",
       "1    C0002  [('C0134', 0.9330356886590646), ('C0159', 0.91...\n",
       "2    C0003  [('C0031', 0.9195362040251337), ('C0152', 0.80...\n",
       "3    C0004  [('C0113', 0.8681637620310363), ('C0012', 0.83...\n",
       "4    C0005  [('C0007', 0.9595673401635022), ('C0146', 0.88...\n",
       "5    C0006  [('C0187', 0.7669275518781463), ('C0169', 0.76...\n",
       "6    C0007  [('C0005', 0.9595673401635022), ('C0140', 0.87...\n",
       "7    C0008  [('C0098', 0.7927078262500883), ('C0194', 0.77...\n",
       "8    C0009  [('C0198', 0.9338276912431526), ('C0010', 0.84...\n",
       "9    C0010  [('C0111', 0.9017605958313126), ('C0062', 0.89...\n",
       "10   C0011  [('C0153', 0.8697689581026931), ('C0126', 0.77...\n",
       "11   C0012  [('C0104', 0.9139567967558033), ('C0152', 0.89...\n",
       "12   C0013  [('C0188', 0.8763216361016894), ('C0099', 0.86...\n",
       "13   C0014  [('C0060', 0.9814851639655328), ('C0198', 0.88...\n",
       "14   C0015  [('C0036', 0.9133874291050558), ('C0144', 0.90...\n",
       "15   C0016  [('C0183', 0.8171306746865663), ('C0117', 0.77...\n",
       "16   C0017  [('C0075', 0.9063812623664969), ('C0057', 0.78...\n",
       "17   C0018  [('C0125', 0.8328130980174581), ('C0050', 0.82...\n",
       "18   C0019  [('C0070', 0.787728756527267), ('C0121', 0.736...\n",
       "19   C0020  [('C0050', 0.7949734014471683), ('C0058', 0.78..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookalike_df = pd.read_csv('Chirag_Gupta_Lookalike.csv')\n",
    "lookalike_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
